---
layout: post
title: "Day 31 – Data Preprocessing, XGBoost Training, and Dataset Cleanup "
date: 2025-07-08
author: Cara Hicks
permalink: /day31.html
tags: ["GitHub", "Data Cleaning", "XGBOOST","Keras", "AI Model"]

what_i_learned: |
    We began Day 31 by reviewing our to do list for the day. Our first task was data preprocessing, which involved cleaning a newly acquired dataset and detecting the Fitzpatrick skin types, ensuring we converted them to match the other scales we’ve been using. Next, we trained a binary classification model using XGBoost. After lunch, we resumed cleaning the new datasets, which differed significantly from the ones we worked with earlier in the program, requiring additional adjustments. As always, we ended the day by publishing our daily blog post.
    
blockers: |
    The only blocker today was dataset cleaning. It honestly felt like a bit of a step back having to rework and clean the new data to fit our model. However, I understand the value because it’s a step that will ultimately improve the model’s performance and prediction. Plus, it was a suggestion we received and chose to implement, knowing it would lead to better results in the long run.

reflection: |
    Today was a good day. I saw it as a bit of a refresher, since we haven’t done this level of data cleaning since the very beginning of the program. Staying positive helps me avoid viewing the task as overwhelming or daunting. Lately, I’ve been thinking that the limited availability of skin cancer datasets might be due to privacy concerns, which is completely understandable, but it also adds a challenge to our work.
---
